{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f39d4e",
   "metadata": {},
   "source": [
    "# Description de données par un modèle affine via une descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a1610",
   "metadata": {},
   "source": [
    "### *Enoncé*\n",
    "\n",
    "On prend comme cas d'études des données $\\boldsymbol{x}$ et $\\boldsymbol{y}$ liées par **une relation affine** de paramètres :\n",
    "* coefficient directeur : $\\boldsymbol{a = 2}$\n",
    "* ordonnée à l'origine :  $\\boldsymbol{b = 0.5}$\n",
    "\n",
    "polluées par un bruit centré obéissant à ***une loi normale d'écart-type 0.2***\n",
    "\n",
    "Créer une fonction `DGd` permettant, ***à partir d'un enregistrement de*** $\\boldsymbol{N}$ ***couples*** $\\boldsymbol{\\{\\,x_{[i]}\\,,\\,y_{[i]}\\,\\}}$, d'obtenir via l'algorithme de **descente de gradient** les paramètres de la relation qui lie ces 2 variables. Cette fonction prendra 5 paramètres d'entrée :\n",
    "* **x** : les données $x$\n",
    "* **y** : les données $y$\n",
    "* **Theta0** : valeur initiale du vecteur de paramètres *(défini comme un np.array)* \n",
    "* **lrate** : gain du gradient *(learning rate)*\n",
    "* **Nbmax** : nombre d'itérations maximales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a486a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x7fee3433d8e0>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a361e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = 2\n",
    "theta2 = 0.5\n",
    "bruit = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72720158",
   "metadata": {},
   "source": [
    "On travaillera tout d'abord sur un premier enregistrement de **11 couples** $\\boldsymbol{\\{\\,x_{[i]}\\,,\\,y_{[i]}\\,\\}}$ avec $\\boldsymbol{x\\in[\\,0\\,,\\,1\\,]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0bbe71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,11)\n",
    "y = theta1*x + theta2 + bruit*np.random.randn(len(x))\n",
    "\n",
    "plt.figure(0,figsize=(12,8))\n",
    "plt.scatter(x, y, label=\"données enregistrées\")\n",
    "plt.xlabel('variable x', fontsize=18)\n",
    "plt.ylabel('variable y', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2322751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGd(x,y,Theta0,lrate,Nbmax):\n",
    "    N = len(x)\n",
    "    Theta = np.zeros((2,Nbmax+1))\n",
    "    Theta[:,0] = Theta0\n",
    "\n",
    "    for i in range(Nbmax):\n",
    "        V = y - ( Theta[0,i]*x + Theta[1,i] )\n",
    "        M = np.hstack( ( -x.reshape(-1,1) , -np.ones((N,1) ) ))\n",
    "        Theta[:,i+1] = Theta[:,i] - lrate*2*M.T.dot(V)\n",
    "            \n",
    "    V = y - ( Theta[0,-1]*x + Theta[1,-1] )\n",
    "    coutfinal = V.T.dot(V)\n",
    "    print('Les paramètres de la droite sont a = {:.4f} et b = {:.4f} ]'\n",
    "          .format(Theta[0,-1],Theta[1,-1]))\n",
    "    print('La somme des carrés des erreurs de modélisation est : {:.4f}'.format(coutfinal))\n",
    "    \n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(x, y, c='b', label=\"données enregistrées\")\n",
    "    plt.plot(x,Theta[0,-1]*x + Theta[1,-1], c='r', label=\"données modélisées\")\n",
    "    plt.xlabel('variable x', fontsize=18)\n",
    "    plt.ylabel('variable y', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(2,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(np.linspace(0,Nbmax,Nbmax+1), Theta[0,:], c = 'b', label = \"theta1 (coef directeur)\")\n",
    "    plt.scatter(np.linspace(0,Nbmax,Nbmax+1), Theta[1,:], c = 'c', label = \"theta2 (ordonnée origine)\")\n",
    "    plt.xlabel('itérations', fontsize=18)\n",
    "    plt.ylabel('paramètres', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f6fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les paramètres de la droite sont a = 2.1674 et b = 0.3690 ]\n",
      "La somme des carrés des erreurs de modélisation est : 0.1368\n"
     ]
    }
   ],
   "source": [
    "DGd(x,y,np.array([ 0 , 0 ]),0.05,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00b6a8",
   "metadata": {},
   "source": [
    "On considère ensuite un second enregistrement de **101 couples** $\\boldsymbol{\\{\\,x_{[i]}\\,,\\,y_{[i]}\\,\\}}$ avec toujours $\\boldsymbol{x\\in[\\,0\\,,\\,1\\,]}$\n",
    "\n",
    "x = np.linspace(0,1,101)\n",
    "y = theta1*x + theta2 + bruit*np.random.randn(len(x))\n",
    "\n",
    "plt.figure(0,figsize=(12,8))\n",
    "plt.clf()\n",
    "plt.scatter(x, y, label=\"données enregistrées\")\n",
    "plt.xlabel('variable x', fontsize=18)\n",
    "plt.ylabel('variable y', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "DGd(x,y,np.array([ 0 , 0 ]),0.005,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57a8e6",
   "metadata": {},
   "source": [
    "Pour traiter le second jeu de données expérimentales, il a fallu **diviser le gain d'apprentissage par 10**  \n",
    "$\\boldsymbol{\\rightarrow}$ **cela est tout à fait normal**  \n",
    "- puisqu'il y a 10 fois plus de données\n",
    "- la fonction coût *(qui est la somme des carrés des erreurs)* aura une amplitude 10 fois plus importante\n",
    "- et donc il en sera de même pour son gradient *(puisqu'il indique la variation de la fonction coût)*  \n",
    "\n",
    "**En conséquence, le gain d'apprentissage doit toujours être normalisé par le nombre de données**, de façon qu'on puisse traiter n'importe quelle taille de jeu de données sans qu'il soit nécessaire de retoucher le gain à chaque fois  \n",
    "On prendra également comme crière de performance, non pas la somme des carrés des erreurs, mais le carré de l'erreur moyenne sur une donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd51746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGd2(x,y,Theta0,lrate,Nbmax):\n",
    "    N = len(x)\n",
    "    Theta = np.zeros((2,Nbmax+1))\n",
    "    Theta[:,0] = Theta0\n",
    "\n",
    "    for i in range(Nbmax):\n",
    "        V = y - ( Theta[0,i]*x + Theta[1,i] )\n",
    "        M = np.hstack( ( -x.reshape(-1,1) , -np.ones((N,1) ) ))\n",
    "        Theta[:,i+1] = Theta[:,i] - (lrate/N)*2*M.T.dot(V)\n",
    "            \n",
    "    V = y - ( Theta[0,-1]*x + Theta[1,-1] )\n",
    "    coutfinal = (1/N)*V.T.dot(V)\n",
    "    print('Les paramètres de la droite sont a = {:.4f} et b = {:.4f} ]'\n",
    "          .format(Theta[0,-1],Theta[1,-1]))\n",
    "    print('Erreur de modélisation moyenne au carré : {:.4f}'.format(coutfinal))\n",
    "    \n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(x, y, c='b', label=\"données enregistrées\")\n",
    "    plt.plot(x,Theta[0,-1]*x + Theta[1,-1], c='r', label=\"données modélisées\")\n",
    "    plt.xlabel('variable x', fontsize=18)\n",
    "    plt.ylabel('variable y', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(2,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(np.linspace(0,Nbmax,Nbmax+1), Theta[0,:], c = 'b', label = \"theta1 (coef directeur)\")\n",
    "    plt.scatter(np.linspace(0,Nbmax,Nbmax+1), Theta[1,:], c = 'c', label = \"theta2 (ordonnée origine)\")\n",
    "    plt.xlabel('itérations', fontsize=18)\n",
    "    plt.ylabel('paramètres', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "262b808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les paramètres de la droite sont a = 1.9017 et b = 0.5518 ]\n",
      "Erreur de modélisation moyenne au carré : 0.0377\n"
     ]
    }
   ],
   "source": [
    "DGd2(x,y,np.array([ 0 , 0 ]),0.5,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbaf7f6",
   "metadata": {},
   "source": [
    "On peut ainsi considérer un troisième enregistrement de **1001 couples** $\\boldsymbol{\\{\\,x_{[i]}\\,,\\,y_{[i]}\\,\\}}$ avec  $\\boldsymbol{x\\in[\\,0\\,,\\,1\\,]}$ sans avoir à retoucher au gain d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa96578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,1001)\n",
    "y = theta1*x + theta2 + bruit*np.random.randn(len(x))\n",
    "\n",
    "plt.figure(0,figsize=(12,8))\n",
    "plt.clf()\n",
    "plt.scatter(x, y, label=\"données enregistrées\")\n",
    "plt.xlabel('variable x', fontsize=18)\n",
    "plt.ylabel('variable y', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2670afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les paramètres de la droite sont a = 2.0157 et b = 0.4969 ]\n",
      "Erreur de modélisation moyenne au carré : 0.0432\n"
     ]
    }
   ],
   "source": [
    "DGd2(x,y,np.array([ 0 , 0 ]),0.5,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e92f4c",
   "metadata": {},
   "source": [
    "On considère maintenant un quatrième et dernier enregistrement de **1001 couples** $\\boldsymbol{\\{\\,x_{[i]}\\,,\\,y_{[i]}\\,\\}}$ avec cette fois $\\boldsymbol{x\\in[\\,0\\,,\\,10\\,]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d15a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,1001)\n",
    "y = theta1*x + theta2 + bruit*np.random.randn(len(x))\n",
    "\n",
    "plt.figure(0,figsize=(12,8))\n",
    "plt.clf()\n",
    "plt.scatter(x, y, label=\"données enregistrées\")\n",
    "plt.xlabel('variable x', fontsize=18)\n",
    "plt.ylabel('variable y', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63a217f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les paramètres de la droite sont a = 2.0237 et b = 0.3438 ]\n",
      "Erreur de modélisation moyenne au carré : 0.0461\n"
     ]
    }
   ],
   "source": [
    "DGd2(x,y,np.array([ 0 , 0 ]),0.005,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21edca7",
   "metadata": {},
   "source": [
    "Une nouvelle fois, il a fallu réduire largement le gain d'apprentissage pour obtenir la convergence des paramètres  \n",
    "$\\boldsymbol{\\rightarrow}$  **encore une fois, c'est tout à fait normal**  \n",
    "- le gradient de la fonction coût par rapport au paramètre $a$ est la variable $x$\n",
    "- la variable $x$ prenant cette fois des valeurs beaucoup plus importantes *(puisque $x$ monte jusque 10 désormais)*, le gradient va augmenter, ce qui oblige à baisser le gain d'apprentissage pour ne pas faire de trop grand pas\n",
    "\n",
    "Pour ne pas être tributaire de la valeur brute des paramètres, il est **sain de les normaliser entre 0 et** $\\boldsymbol{\\pm}1$ avant de lancer la modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f1f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGd3(x,y,Theta0,lrate,Nbmax):\n",
    "    Mx = np.max(x)\n",
    "    xn = x / Mx\n",
    "    My = np.max(y)\n",
    "    yn = y / My\n",
    "    N = len(x)\n",
    "    Theta = np.zeros((2,Nbmax+1))\n",
    "    Theta[:,0] = Theta0\n",
    "    \n",
    "    for i in range(Nbmax):\n",
    "        V = yn - ( Theta[0,i]*xn + Theta[1,i] )\n",
    "        M = np.hstack( ( -xn.reshape(-1,1) , -np.ones((N,1) ) ))\n",
    "        Theta[:,i+1] = Theta[:,i] - (lrate/N)*2*M.T.dot(V)\n",
    "        \n",
    "    a = Theta[0,-1]*My/Mx\n",
    "    b = Theta[1,-1]*My\n",
    "            \n",
    "    V = y - ( a*x + b )\n",
    "    coutfinal = (1/N)*V.T.dot(V)    \n",
    "    print('Les paramètres de la droite sont a = {:.4f} et b = {:.4f}'\n",
    "          .format(a,b))\n",
    "    print('Erreur de modélisation moyenne au carré : {:.4f}'.format(coutfinal))\n",
    "    \n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(x, y, c='b', label=\"données enregistrées\")\n",
    "    plt.plot(x,a*x + b, c='r', label=\"données modélisées\")\n",
    "    plt.xlabel('variable x', fontsize=18)\n",
    "    plt.ylabel('variable y', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(2,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(np.linspace(0,Nbmax,Nbmax+1), Theta[0,:]*My/Mx, c = 'b', label = \"theta1 (coef directeur)\")\n",
    "    plt.scatter(np.linspace(0,Nbmax,Nbmax+1), Theta[1,:]*My, c = 'c', label = \"theta2 (ordonnée origine)\")\n",
    "    plt.xlabel('itérations', fontsize=18)\n",
    "    plt.ylabel('paramètres', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea4caebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les paramètres de la droite sont a = 2.0017 et b = 0.4872\n",
      "Erreur de modélisation moyenne au carré : 0.0416\n"
     ]
    }
   ],
   "source": [
    "DGd3(x,y,np.array([ 0 , 0 ]),0.5,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d30eed",
   "metadata": {},
   "source": [
    "Pour alléger le coût du calcul du gradient à chaque itération, on peut se tourner vers **une descente de gradient stochastique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ec8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGd4(x,y,Theta0,lrate,Nbmax,batch):\n",
    "    \n",
    "    Mx = np.max(x)\n",
    "    xn = x / Mx\n",
    "    My = np.max(y)\n",
    "    yn = y / My\n",
    "    \n",
    "    N = len(x)\n",
    "    Nbatch = int(N//batch)\n",
    "    epoch = int(Nbmax//Nbatch+1)\n",
    "    iterations = epoch*Nbatch\n",
    "    Theta = np.zeros((2,iterations+1))\n",
    "    Theta[:,0] = Theta0\n",
    "    \n",
    "    print('La taille du batch est :',batch)\n",
    "    print('donc le nombre de batch pour couvrir le jeu de données est :',Nbatch)\n",
    "    print('Le nombre de passe pour au moins atteindre le nombre d\\'itérations max est :',epoch)\n",
    "    print('ce qui conduit au total à',iterations,'itérations où l\\'on manipule des matrices de dimension : ',\n",
    "          batch,'x 2')\n",
    "    \n",
    "    Data = np.hstack((xn.reshape(-1,1),yn.reshape(-1,1)))\n",
    "    \n",
    "    iter = 0\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        np.random.shuffle(Data)\n",
    "        for j in range(Nbatch):\n",
    "            V = Data[batch*j:batch*(j+1),1] - ( Theta[0,iter]*Data[batch*j:batch*(j+1),0] + Theta[1,iter] )\n",
    "            M = np.hstack( ( -Data[batch*j:batch*(j+1),0].reshape(-1,1) , -np.ones((batch,1)) ))\n",
    "            Theta[:,iter+1] = Theta[:,iter] - (lrate/batch)*2*M.T.dot(V)\n",
    "            iter += 1\n",
    "            \n",
    "    a = Theta[0,-1]*My/Mx\n",
    "    b = Theta[1,-1]*My\n",
    "            \n",
    "    V = y - ( a*x + b )\n",
    "    coutfinal = (1/N)*V.T.dot(V)\n",
    "    print('Les paramètres de la droite sont a = {:.4f} et b = {:.4f}'\n",
    "          .format(a,b))\n",
    "    print('Erreur de modélisation moyenne au carré : {:.4f}'.format(coutfinal))\n",
    "    \n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(x, y, c='b', label=\"données enregistrées\")\n",
    "    plt.plot(x,a*x + b, c='r', label=\"données modélisées\")\n",
    "    plt.xlabel('variable x', fontsize=18)\n",
    "    plt.ylabel('variable y', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(2,figsize=(12,8))\n",
    "    plt.clf()\n",
    "    plt.scatter(np.linspace(0,iterations,iterations+1), Theta[0,:]*My/Mx, c = 'b', label = \"theta1 (coef directeur)\")\n",
    "    plt.scatter(np.linspace(0,iterations,iterations+1), Theta[1,:]*My, c = 'c', label = \"theta2 (ordonnée origine)\")\n",
    "    plt.xlabel('itérations', fontsize=18)\n",
    "    plt.ylabel('paramètres', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13bbea6",
   "metadata": {},
   "source": [
    "Bien entendu, si ***la taille du batch est égale à la taille des données***, alors les 2 algorithmes de descente de gradient et de descente de gradient stochastique sont identiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8387c504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du batch est : 1001\n",
      "donc le nombre de batch pour couvrir le jeu de données est : 1\n",
      "Le nombre de passe pour au moins atteindre le nombre d'itérations max est : 101\n",
      "ce qui conduit au total à 101 itérations où l'on manipule des matrices de dimension :  1001 x 2\n",
      "Les paramètres de la droite sont a = 2.0018 et b = 0.4866\n",
      "Erreur de modélisation moyenne au carré : 0.0416\n"
     ]
    }
   ],
   "source": [
    "DGd4(x,y,np.array([ 0 , 0 ]),0.5,100,len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c2619",
   "metadata": {},
   "source": [
    "Ensuite, ***plus on réduit la taille du batch***, moins le coût calculatoire par itération est important, mais plus l'approximation du gradient est bruitée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74447343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du batch est : 100\n",
      "donc le nombre de batch pour couvrir le jeu de données est : 10\n",
      "Le nombre de passe pour au moins atteindre le nombre d'itérations max est : 11\n",
      "ce qui conduit au total à 110 itérations où l'on manipule des matrices de dimension :  100 x 2\n",
      "Les paramètres de la droite sont a = 2.0009 et b = 0.4601\n",
      "Erreur de modélisation moyenne au carré : 0.0425\n"
     ]
    }
   ],
   "source": [
    "DGd4(x,y,np.array([ 0 , 0 ]),0.5,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93547a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du batch est : 10\n",
      "donc le nombre de batch pour couvrir le jeu de données est : 100\n",
      "Le nombre de passe pour au moins atteindre le nombre d'itérations max est : 2\n",
      "ce qui conduit au total à 200 itérations où l'on manipule des matrices de dimension :  10 x 2\n",
      "Les paramètres de la droite sont a = 1.9993 et b = 0.5673\n",
      "Erreur de modélisation moyenne au carré : 0.0464\n"
     ]
    }
   ],
   "source": [
    "DGd4(x,y,np.array([ 0 , 0 ]),0.5,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d0e13b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du batch est : 4\n",
      "donc le nombre de batch pour couvrir le jeu de données est : 250\n",
      "Le nombre de passe pour au moins atteindre le nombre d'itérations max est : 1\n",
      "ce qui conduit au total à 250 itérations où l'on manipule des matrices de dimension :  4 x 2\n",
      "Les paramètres de la droite sont a = 2.0155 et b = 0.4999\n",
      "Erreur de modélisation moyenne au carré : 0.0495\n"
     ]
    }
   ],
   "source": [
    "DGd4(x,y,np.array([ 0 , 0 ]),0.5,100,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94af78ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du batch est : 1\n",
      "donc le nombre de batch pour couvrir le jeu de données est : 1001\n",
      "Le nombre de passe pour au moins atteindre le nombre d'itérations max est : 1\n",
      "ce qui conduit au total à 1001 itérations où l'on manipule des matrices de dimension :  1 x 2\n",
      "Les paramètres de la droite sont a = 1.9547 et b = 0.5388\n",
      "Erreur de modélisation moyenne au carré : 0.0949\n"
     ]
    }
   ],
   "source": [
    "DGd4(x,y,np.array([ 0 , 0 ]),0.5,100,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
